# VLM Geometry Bench - Claude Code Guidance

## Project Overview

Benchmark for evaluating Vision Language Models' ability to identify, count, and locate simple geometric shapes. Combines:
- Test suite generation from `d:\python\imagegen` (synthetic images with known ground truth)
- Evaluation framework adapted from `d:\python\salbench` (VLM API integration, metrics, reporting)

## Related Repositories

- `d:\python\imagegen` - Generates test images with 6 classes (CTRL, USSS, USDS, HSFR, HSRP, HSDN)
- `d:\python\salbench` - Reference implementation for VLM evaluation (we added the evaluation/ module)

## Test Suite

The test suite is generated by imagegen and stored at `d:\python\imagegen\testsuite\`.

**Contents:** 92 images across 6 classes:
- CTRL: 2 images (empty, single spot)
- USSS: 36 images (uniform spots same size)
- USDS: 9 images (uniform spots different sizes)
- HSFR: 3 images (hexagonal fixed rigid)
- HSRP: 24 images (hexagonal random perturbation)
- HSDN: 18 images (hexagonal defects + noise)

**To regenerate:**
```bash
cd d:\python\imagegen
uv run gentestsuite testsuite-config.yaml --output-dir ./testsuite
```

## Architecture

See `docs/ARCHITECTURE.md` for detailed diagrams and component descriptions.

Key components:
- `config.py` - EvaluationConfig dataclass
- `vision_client.py` - VLM API communication (Ollama, OpenRouter, Anthropic)
- `data_loader.py` - Load imagegen test suite + manifest
- `prompts.py` - Task-specific prompts (COUNT, LOCATE, PATTERN, SIZE, DEFECT)
- `response_parser.py` - Parse VLM responses to structured data
- `metrics.py` - Compute accuracy metrics
- `evaluator.py` - Main orchestration
- `reporter.py` - Results output (JSON, CSV, console)
- `__main__.py` - CLI entry point

## Commands

```bash
# Install dependencies
uv sync

# Show CLI help
uv run vlm-geometry-bench --help

# Run evaluation with local Ollama
uv run vlm-geometry-bench --backend ollama --model llava:7b \
    --testsuite d:/python/imagegen/testsuite

# Run quick test (5 samples, 2 classes)
uv run vlm-geometry-bench --samples 5 --classes CTRL,USSS --tasks COUNT

# Run with OpenRouter
uv run vlm-geometry-bench --backend openrouter --model openai/gpt-4o \
    --testsuite d:/python/imagegen/testsuite

# Run with Anthropic API
uv run vlm-geometry-bench --backend anthropic --model claude-sonnet-4-20250514 \
    --testsuite d:/python/imagegen/testsuite

# Run tests
uv run pytest
```

## Code Style

- Use `rich` for console output
- Use `rich-click` for CLI
- Dataclasses for configuration
- Type hints throughout
- Async/await for API calls

## Testing

- pytest with fixtures
- Mock VLM API responses
- Test with sample manifest/images from imagegen
